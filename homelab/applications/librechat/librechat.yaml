version: 1.2.1
 
cache: true
 
interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
 
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true

  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
 
registration:
  socialLogins: []
 
endpoints:
  custom:
 
    # groq
    - name: "groq"
      apiKey: "${LIBRECHAT_GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "deepseek-r1-distill-llama-70b",
          "deepseek-r1-distill-qwen-32b",
          "llama-3.3-70b-versatile",
          "qwen-2.5-32b",
          "mixtral-8x7b-32768"
        ]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-r1-distill-llama-70b"
      modelDisplayLabel: "Deepseek R1 Distill Lama"
 
    # Mistral AI API
    - name: "Mistral"
      apiKey: "${LIBRECHAT_MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default: [
          "codestral-latest",
          "mistral-large-latest",
          "pixtral-large-latest"
        ]
        fetch: true
      titleConvo: true
      titleModel: "mistral-large-latest"
      modelDisplayLabel: "Mistral Large"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # Deepseek
    - name: "Deepseek"
      apiKey: "${LIBRECHAT_DEEPSEEK_API_KEY}"
      baseURL: "https://api.deepseek.com/v1"
      models:
        default: [
          "deepseek-chat", 
          "deepseek-coder", 
          "deepseek-reasoner"
        ]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      modelDisplayLabel: "Deepseek Chat"